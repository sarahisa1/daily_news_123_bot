#!/usr/bin/env python3
"""
ğŸ“Š ì¼ì¼ ê²½ì œ ë‰´ìŠ¤ TOP10 í…”ë ˆê·¸ë¨ ë´‡ (GitHub Actions ë²„ì „)
ë§¤ì¼ ìë™ìœ¼ë¡œ ê²½ì œ/ì£¼ì‹/í•´ì™¸ì£¼ì‹/ì›ìì¬/ì•”í˜¸í™”í ë‰´ìŠ¤ë¥¼ ë°œì†¡í•©ë‹ˆë‹¤.

GitHub Actionsì—ì„œ ì‹¤í–‰ë˜ë©°, í™˜ê²½ë³€ìˆ˜ë¡œ ì„¤ì •ì„ ë°›ìŠµë‹ˆë‹¤.
"""

import asyncio
import aiohttp
from datetime import datetime
from bs4 import BeautifulSoup
import telegram
from telegram.constants import ParseMode
import logging
import os
import sys

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# í™˜ê²½ë³€ìˆ˜ì—ì„œ ì„¤ì • ì½ê¸°
BOT_TOKEN = os.environ.get('BOT_TOKEN')
CHAT_ID = os.environ.get('CHAT_ID')


class NewsCollector:
    """ë‰´ìŠ¤ ìˆ˜ì§‘ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
        }
    
    async def fetch_page(self, session, url):
        """ì›¹ í˜ì´ì§€ ê°€ì ¸ì˜¤ê¸°"""
        try:
            async with session.get(url, headers=self.headers, timeout=15) as response:
                return await response.text()
        except Exception as e:
            logger.error(f"í˜ì´ì§€ ë¡œë“œ ì‹¤íŒ¨: {url} - {e}")
            return None

    async def get_naver_economy_news(self, session):
        """ë„¤ì´ë²„ ê²½ì œ ë‰´ìŠ¤ TOP10"""
        url = "https://news.naver.com/section/101"
        news_list = []
        
        try:
            html = await self.fetch_page(session, url)
            if html:
                soup = BeautifulSoup(html, 'html.parser')
                headlines = soup.select('.sa_text_title')[:10]
                for idx, item in enumerate(headlines, 1):
                    title = item.get_text(strip=True)
                    link = item.get('href', '')
                    if title and link:
                        news_list.append({
                            'rank': idx,
                            'title': title[:60] + '...' if len(title) > 60 else title,
                            'link': link
                        })
        except Exception as e:
            logger.error(f"ë„¤ì´ë²„ ê²½ì œ ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
        
        return news_list

    async def get_stock_news(self, session):
        """êµ­ë‚´ ì£¼ì‹ ë‰´ìŠ¤ TOP10"""
        url = "https://finance.naver.com/news/mainnews.naver"
        news_list = []
        
        try:
            html = await self.fetch_page(session, url)
            if html:
                soup = BeautifulSoup(html, 'html.parser')
                items = soup.select('.articleSubject a')[:10]
                for idx, item in enumerate(items, 1):
                    title = item.get_text(strip=True)
                    link = "https://finance.naver.com" + item.get('href', '')
                    if title:
                        news_list.append({
                            'rank': idx,
                            'title': title[:60] + '...' if len(title) > 60 else title,
                            'link': link
                        })
        except Exception as e:
            logger.error(f"êµ­ë‚´ ì£¼ì‹ ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
        
        return news_list

    async def get_world_stock_news(self, session):
        """í•´ì™¸ ì£¼ì‹ ë‰´ìŠ¤ TOP10"""
        url = "https://finance.naver.com/world/"
        news_list = []
        
        try:
            html = await self.fetch_page(session, url)
            if html:
                soup = BeautifulSoup(html, 'html.parser')
                items = soup.select('.news_list li a')[:10]
                for idx, item in enumerate(items, 1):
                    title = item.get_text(strip=True)
                    link = item.get('href', '')
                    if not link.startswith('http'):
                        link = "https://finance.naver.com" + link
                    if title:
                        news_list.append({
                            'rank': idx,
                            'title': title[:60] + '...' if len(title) > 60 else title,
                            'link': link
                        })
        except Exception as e:
            logger.error(f"í•´ì™¸ ì£¼ì‹ ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
        
        return news_list

    async def get_commodity_news(self, session):
        """ì›ìì¬ ë‰´ìŠ¤ TOP10"""
        url = "https://search.naver.com/search.naver?where=news&query=ì›ìì¬+ê¸ˆ+ìœ ê°€+ì‹œì„¸"
        news_list = []
        
        try:
            html = await self.fetch_page(session, url)
            if html:
                soup = BeautifulSoup(html, 'html.parser')
                items = soup.select('.news_tit')[:10]
                for idx, item in enumerate(items, 1):
                    title = item.get_text(strip=True)
                    link = item.get('href', '')
                    if title:
                        news_list.append({
                            'rank': idx,
                            'title': title[:60] + '...' if len(title) > 60 else title,
                            'link': link
                        })
        except Exception as e:
            logger.error(f"ì›ìì¬ ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
        
        return news_list

    async def get_crypto_news(self, session):
        """ì•”í˜¸í™”í ë‰´ìŠ¤ TOP10"""
        url = "https://search.naver.com/search.naver?where=news&query=ë¹„íŠ¸ì½”ì¸+ì•”í˜¸í™”í+ì´ë”ë¦¬ì›€"
        news_list = []
        
        try:
            html = await self.fetch_page(session, url)
            if html:
                soup = BeautifulSoup(html, 'html.parser')
                items = soup.select('.news_tit')[:10]
                for idx, item in enumerate(items, 1):
                    title = item.get_text(strip=True)
                    link = item.get('href', '')
                    if title:
                        news_list.append({
                            'rank': idx,
                            'title': title[:60] + '...' if len(title) > 60 else title,
                            'link': link
                        })
        except Exception as e:
            logger.error(f"ì•”í˜¸í™”í ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
        
        return news_list

    async def get_market_indices(self, session):
        """ì£¼ìš” ì‹œì¥ ì§€ìˆ˜ ê°€ì ¸ì˜¤ê¸°"""
        indices = {}
        
        # êµ­ë‚´ ì§€ìˆ˜
        url = "https://finance.naver.com/sise/"
        try:
            html = await self.fetch_page(session, url)
            if html:
                soup = BeautifulSoup(html, 'html.parser')
                kospi = soup.select_one('#KOSPI_now')
                if kospi:
                    indices['KOSPI'] = kospi.get_text(strip=True)
                kosdaq = soup.select_one('#KOSDAQ_now')
                if kosdaq:
                    indices['KOSDAQ'] = kosdaq.get_text(strip=True)
        except Exception as e:
            logger.error(f"êµ­ë‚´ ì§€ìˆ˜ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
        
        # í•´ì™¸ ì§€ìˆ˜
        world_url = "https://finance.naver.com/world/"
        try:
            html = await self.fetch_page(session, world_url)
            if html:
                soup = BeautifulSoup(html, 'html.parser')
                world_indices = soup.select('.data_lst tr')
                for row in world_indices[:5]:
                    name_elem = row.select_one('.name')
                    value_elem = row.select_one('.point')
                    if name_elem and value_elem:
                        name = name_elem.get_text(strip=True)
                        value = value_elem.get_text(strip=True)
                        indices[name] = value
        except Exception as e:
            logger.error(f"í•´ì™¸ ì§€ìˆ˜ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
        
        return indices

    async def collect_all_news(self):
        """ëª¨ë“  ë‰´ìŠ¤ ìˆ˜ì§‘"""
        async with aiohttp.ClientSession() as session:
            results = await asyncio.gather(
                self.get_naver_economy_news(session),
                self.get_stock_news(session),
                self.get_world_stock_news(session),
                self.get_commodity_news(session),
                self.get_crypto_news(session),
                self.get_market_indices(session),
                return_exceptions=True
            )
            
            return {
                'economy': results[0] if not isinstance(results[0], Exception) else [],
                'stock': results[1] if not isinstance(results[1], Exception) else [],
                'world_stock': results[2] if not isinstance(results[2], Exception) else [],
                'commodity': results[3] if not isinstance(results[3], Exception) else [],
                'crypto': results[4] if not isinstance(results[4], Exception) else [],
                'indices': results[5] if not isinstance(results[5], Exception) else {}
            }


class TelegramNewsBot:
    """í…”ë ˆê·¸ë¨ ë‰´ìŠ¤ ë´‡"""
    
    def __init__(self, token, chat_id):
        self.bot = telegram.Bot(token=token)
        self.chat_id = chat_id
        self.collector = NewsCollector()
    
    def format_news_message(self, news_data):
        """ë‰´ìŠ¤ ë©”ì‹œì§€ í¬ë§·íŒ…"""
        today = datetime.now().strftime('%Yë…„ %mì›” %dì¼ (%a)')
        
        message = f"""
ğŸ“° <b>ì¼ì¼ ê²½ì œ ë‰´ìŠ¤ TOP10</b>
ğŸ“… {today}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

"""
        # ì‹œì¥ ì§€ìˆ˜
        if news_data.get('indices'):
            message += "ğŸ“Š <b>ì£¼ìš” ì‹œì¥ ì§€ìˆ˜</b>\n"
            for name, value in news_data['indices'].items():
                message += f"  â€¢ {name}: {value}\n"
            message += "\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n\n"
        
        # ê° ì¹´í…Œê³ ë¦¬ë³„ ë‰´ìŠ¤
        categories = [
            ('economy', 'ğŸ’° ê²½ì œ ë‰´ìŠ¤ TOP5'),
            ('stock', 'ğŸ“ˆ êµ­ë‚´ ì£¼ì‹ ë‰´ìŠ¤ TOP5'),
            ('world_stock', 'ğŸŒ í•´ì™¸ ì£¼ì‹ ë‰´ìŠ¤ TOP5'),
            ('commodity', 'ğŸ›¢ï¸ ì›ìì¬ ë‰´ìŠ¤ TOP5'),
            ('crypto', 'â‚¿ ì•”í˜¸í™”í ë‰´ìŠ¤ TOP5'),
        ]
        
        for key, title in categories:
            news_list = news_data.get(key, [])
            if news_list:
                message += f"<b>{title}</b>\n\n"
                for news in news_list[:5]:
                    message += f"{news['rank']}. {news['title']}\n"
                message += "\n"
        
        message += """â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ¤– Powered by GitHub Actions
"""
        return message

    def format_detailed_message(self, news_data, category, title):
        """ì¹´í…Œê³ ë¦¬ë³„ ìƒì„¸ ë©”ì‹œì§€ (ë§í¬ í¬í•¨)"""
        news_list = news_data.get(category, [])
        if not news_list:
            return None
        
        message = f"<b>{title}</b>\n\n"
        for news in news_list[:10]:
            message += f"{news['rank']}. <a href='{news['link']}'>{news['title']}</a>\n\n"
        
        return message

    async def send_news(self):
        """ë‰´ìŠ¤ ë°œì†¡"""
        logger.info("ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹œì‘...")
        news_data = await self.collector.collect_all_news()
        
        # ìš”ì•½ ë©”ì‹œì§€ ë°œì†¡
        summary_message = self.format_news_message(news_data)
        try:
            await self.bot.send_message(
                chat_id=self.chat_id,
                text=summary_message,
                parse_mode=ParseMode.HTML,
                disable_web_page_preview=True
            )
            logger.info("âœ… ìš”ì•½ ë‰´ìŠ¤ ë°œì†¡ ì™„ë£Œ")
        except Exception as e:
            logger.error(f"âŒ ìš”ì•½ ë©”ì‹œì§€ ë°œì†¡ ì‹¤íŒ¨: {e}")
            raise
        
        # ì¹´í…Œê³ ë¦¬ë³„ ìƒì„¸ ë©”ì‹œì§€ ë°œì†¡
        categories = [
            ('economy', 'ğŸ’° ê²½ì œ ë‰´ìŠ¤ ìƒì„¸'),
            ('stock', 'ğŸ“ˆ êµ­ë‚´ ì£¼ì‹ ë‰´ìŠ¤ ìƒì„¸'),
            ('world_stock', 'ğŸŒ í•´ì™¸ ì£¼ì‹ ë‰´ìŠ¤ ìƒì„¸'),
            ('commodity', 'ğŸ›¢ï¸ ì›ìì¬ ë‰´ìŠ¤ ìƒì„¸'),
            ('crypto', 'â‚¿ ì•”í˜¸í™”í ë‰´ìŠ¤ ìƒì„¸'),
        ]
        
        for key, title in categories:
            detailed_msg = self.format_detailed_message(news_data, key, title)
            if detailed_msg:
                try:
                    await asyncio.sleep(1)  # rate limit ë°©ì§€
                    await self.bot.send_message(
                        chat_id=self.chat_id,
                        text=detailed_msg,
                        parse_mode=ParseMode.HTML,
                        disable_web_page_preview=True
                    )
                    logger.info(f"âœ… {title} ë°œì†¡ ì™„ë£Œ")
                except Exception as e:
                    logger.error(f"âŒ {title} ë°œì†¡ ì‹¤íŒ¨: {e}")
        
        logger.info("ğŸ‰ ëª¨ë“  ë‰´ìŠ¤ ë°œì†¡ ì™„ë£Œ!")


async def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    # í™˜ê²½ë³€ìˆ˜ í™•ì¸
    if not BOT_TOKEN:
        logger.error("âŒ BOT_TOKEN í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        sys.exit(1)
    
    if not CHAT_ID:
        logger.error("âŒ CHAT_ID í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        sys.exit(1)
    
    logger.info(f"ğŸš€ ë´‡ ì‹œì‘ - Chat ID: {CHAT_ID[:4]}***")
    
    bot = TelegramNewsBot(BOT_TOKEN, CHAT_ID)
    await bot.send_news()


if __name__ == "__main__":
    asyncio.run(main())
